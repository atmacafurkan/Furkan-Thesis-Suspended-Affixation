

<<load, echo=FALSE, include=FALSE>>=
# Load R libraries
library(dplyr)
library(brms)
library(magrittr)
library(gdata)
library(tidyr)
library(ggplot2)
library(extrafont)
library(readxl)
library(stringr)
library(grDevices)
library(bayesplot)
library(tidybayes)
`%notin%` <- Negate(`%in%`)
se <- function(x) sd(x)/sqrt(length(x))
theme_set(theme_bw()) # set ggplot theme
bayesplot_theme_set(new = theme_bw()) # set plot view

init_reads <- readRDS("init_reads.rds")
init_subject <- init_reads %>% summarise(x= length(unique(subject)))
init_point <- init_reads %>% subset(experiment !="filler") %>% summarise(x = length(RT)) 

df_reads <- readRDS("df_reads.rds") %>% ungroup()
final_subject <- df_reads %>% summarise(x= length(unique(subject)))
final_point <- df_reads %>% subset(experiment !="filler") %>% summarise(x = length(RT)) 


df_responses <- readRDS("df_responses.rds")
total_response <- df_responses %>% summarise(x = length(correct))
correct_response <- df_responses %>% subset(correct=="1") %>% summarise(x =length(correct))

SA_label <- c("Üzerinde",
              "toz",
              "biriken",
              "masayı",
              "yıkamalı-ymış-ım",
              "ve/ya",
              "silmeliymişim", 
              "diye",
              "mırıldandım",
              "kendi",
              "kendime") %>% enc2utf8()

SA_target <- brm(RT ~ 1 + cat*conjoiner+ (cat*conjoiner | item) + (cat*conjoiner | subject), 
                 data = df_SA_model,
                 family = lognormal('identity'), chains = 4, cores = 4, iter = 2000,
                 file = "model_SA_target")

SA_target_results <- fixef(SA_target, summary = TRUE, robust = FALSE) %>% as.data.frame() %>%
  tibble::rownames_to_column("variables")

@

\SweaveOpts{concordance=TRUE}

\section{Self paced reading}

In the literature of SA, not much exploratory studies are conducted. Although theoretical explorations are made for what it is \citep{kornfilt1996some,kornfilt2012revisiting,kabak2007turkish,broadwell2008turkish}, not much is done for how it operates except than \cite{kharytonava2012word,kharytonava2012taming} which only investigates a particular type of SA in Turkish compounds. My aim in this experiment is to open up an exploratory field for SA in Turkish with emphasis on language processing. For this purposes I alter the conjoiner and amount of SA in the verbal domain. The reason for choosing only verbal domain for this particular experiment is that there are no ambiguities in the verbal domain SA. Dealing with ambiguities in an experimental setting requires a complicated design for determining dependency resolutions. Although it is a venue that also needs to be explored I reserve the investigation of SA in the nominal domain and its processing for another experiment with an actual language modelling which would enable the testing of the hypotheses of the different approaches. That's why, for the sake of sticking with basic exploratory aspects of SA, I have designed an experiment looking at SA in the verbal domain. In the following subsections I lay out the method, results, and analysis of the experiment.

\subsection{Method}
In this subsection I report the participants, materials, and the procedure for the experiment.

\subsubsection{Participants}

The participants were \Sexpr{init_subject$x} students at Boğaziçi University who were native speakers of Turkish. In exchange for their participation they have received 1 point to their overall course score on a chosen linguistics course.

\subsubsection{Materials}

The experiment is comprised of three variables. The first variable is the amount of SA with the levels of No SA, One SA, and Full SA. The second variable is the conjoiner with levels \textit{ve} `and' and \textit{veya} `or'. The third variable is contrast. In this variable one of the suspendable suffixes in the second conjunct is altered to have a mismatch between the first and second conjuncts in terms of clause aspect and agreement. This contrast is only performed on the No SA sentence. This way I end up with 3x2 conditions combining the amount of SA and conjoiner type, plus two conditions where I have a contrasting second conjunct for No SA condition with conjoiners. I have made 24 items for the experiment, by 8 conditions I end up with 192 experimental items, I also added 48 filler items. A latin square design by condition is applied, forming 8 lists of 24. This resulted in each participant seeing only 24 experimental items and 48 fillers. All the experimental items have a three word pre and three word post conjunction regions, see the template in (\ref{selfpacedtemplate}). An example set of experimental items with all conditions is given in (\ref{selfpacedexamples}, only relevant parts of the sentence is presented). Half of the items and fillers had yes/no comprehension questions with the correct option being "yes" and the other half had "no" as the correct answer.
\begin{exe}
\ex \label{selfpacedtemplate}
4WORDS CONJ1 \textit{ve/ya} CONJ2 4WORDS
\end{exe}


\begin{exe}
\ex \label{selfpacedexamples}
    \begin{xlist}
     \ex No SA_{\And} \gll ... yap-sa-ymış-ım ve gönder-se-ymiş-im ... \\ ... do-{\Cond}-{\Prf}-{\First}.{\Sg} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\

     \ex No SA_{\Or} \gll ... yap-sa-ymış-ım veya gönder-se-ymiş-im ... \\ ... do-{\Cond}-{\Prf}-{\First}.{\Sg} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\
     
     \ex One SA_{\And} \gll ... yap-sa-ymış ve gönder-se-ymiş-im ... \\ ... do-{\Cond}-{\Prf} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\
     
     \ex One SA_{\Or} \gll ... yap-sa-ymış veya gönder-se-ymiş-im ... \\ ... do-{\Cond}-{\Prf} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\

     \ex Full SA_{\And} \gll ... yap-sa ve gönder-se-ymiş-im ... \\ ... do-{\Cond} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\
     
     \ex Full SA_{\Or} \gll ... yap-sa veya gönder-se-ymiş-im ... \\ ... do-{\Cond} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\

     
     \ex Contrast_{\And} \gll ... yap-sa-ymış-ız ve gönder-se-ymiş-im ... \\ ... do-{\Cond}-{\Prf}-{\First}.{\Pl} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\
     
     \ex Contrast_{\Or} \gll ... yap-sa-ymış-ız veya gönder-se-ymiş-im ... \\ ... do-{\Cond}-{\Prf}-{\First}.{\Pl} {\And} send-{\Cond}-{\Prf}-{\First}.{\Sg} ... \\

    \end{xlist}
\end{exe}

The experiment is formed using http://spellout.net/ibexfarm/ \citep{drummond2013ibex}, and carried out online. For the full list of items and fillers (1-24 and 100-148), see Appendix \ref{selfpaceditems}.

\subsubsection{Procedure}
Participants are provided a link to the experiment prompting them with a consent page. Upon giving consent participants are run through 5 practice items and then they are prompted again for the beginning of the experiment. Each item is presented word by word, and after the end of every sentence a yes/no comprehension question was asked. Participants professed their choice by pushing "Q" key for "yes" and "P" key for "no". After the experiment is done participants are redirected to a separate page to fill their student information to be relayed to the course's professor for extra credit. This is kept separate of the experiment results, protecting participant anonymity.

\subsubsection{Results}
The resulting csv file of the experiment is brought into R \citep{team2013r} for data cleaning, aggregation, and analysis.
The data consisted of \Sexpr{init_point$x} points before cleaning. Two items with a typo, \Sexpr{init_subject$x-final_subject$x} subjects whose accuracies are below 70\% are excluded from the data. After these exclusions, \Sexpr{round(x = 100*(1-(correct_response$x/total_response$x)), digits = 2)}\% of the trials with incorrect answers are also excluded. The whole cleaning resulted in the loss of \Sexpr{round(x = 100*(1-(final_point$x/init_point$x)), digits = 2)}\% of the data.

\begin{figure}[hbt!]
\centering
<<secondplot, echo=FALSE, dev='cairo_pdf', fig.width=8, fig.height=5, out.width='\linewidth'>>=
df_reads$word_name <- df_reads$word_number %>% as.factor()
df_reads %>% dplyr::select(cat, word_name, RT, conjoiner) %>% ungroup() %>%
  subset(word_name %in% c(1:11) & cat !=  "Contrast") %>% 
  group_by(cat, word_name, conjoiner) %>%
  summarise(average_RT = mean(RT), se = se(RT)) %>%
  ggplot(aes(word_name, average_RT, group = cat, color = cat)) +
  theme(text=element_text(size=12),
        legend.position = "bottom", legend.title = element_blank(),
        axis.text.x = element_text(face = "bold.italic", angle = 30, hjust = 1)) +
  geom_point(aes(shape = cat), size= 2.4, position = position_dodge(0.35)) + 
  geom_line(aes(linetype = cat), position = position_dodge(0.35)) +
  geom_errorbar(aes(ymin = average_RT -se, ymax = average_RT + se),
                alpha = 0.4,
                width = .3, position = position_dodge(0.35), color = "black") +
  scale_x_discrete(labels = SA_label, name ="") + ylab("average RT (ms)") +
  facet_grid(conjoiner~.)
@
\caption{Average reading times for a sentence}
\label{fig:averageRT}
\end{figure}


\begin{figure}[hbt!]
\centering
<<thirdplot, echo=FALSE, dev ='cairo_pdf', out.width='\linewidth', fig.width=4, fig.height=3>>=
mcmc_intervals(SA_target, pars =  paste0("b_", SA_target_results$variables))

@
\caption{Model results}
\label{fig:modelresults}
\end{figure}

